{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd7654a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Colorado Shapefile Import and Schema Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c5600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wells...\n",
      "  Found layers: ['Wells']\n",
      "Processing fields...\n",
      "  Found layers: ['COGCC_Fields', 'COGCC_Horizontal_Fields', 'COGCC_OGDP', 'COGCC_staff_contacts', 'COGCC_Wattenberg_Field']\n",
      "Processing inspections...\n",
      "  Found layers: ['BasicInfo', 'Bradenhead', 'Cement', 'Complaints', 'CorrectiveActions', 'Drill', 'Environmental', 'Idle', 'Locations', 'Pits', 'ProductionComments', 'Reclamations', 'Spills', 'Stimulation', 'StormWater', 'TankBerm', 'Uic', 'WasteManagement', 'WellInfo', 'WorkoverComments']\n",
      "Processing violations...\n",
      "Processing complaints...\n",
      "‚úÖ All Colorado files processed and stored in 'co' schema.\n",
      "üìã Table summary in 'co' schema:\n",
      "- complaints: 6604 rows\n",
      "- fields: 1454 rows\n",
      "- inspections: 229109 rows\n",
      "- violations: 3841 rows\n",
      "- wells: 123576 rows\n",
      "üîÅ Performing spatial joins where applicable:\n",
      "  ‚ö†Ô∏è  Skipping complaints (no geometry or join failed): Query missing geometry column 'geometry'\n",
      "  ‚úÖ fields_joined created\n",
      "  ‚ö†Ô∏è  Skipping inspections (no geometry or join failed): Query missing geometry column 'geometry'\n",
      "  ‚ö†Ô∏è  Skipping violations (no geometry or join failed): Query missing geometry column 'geometry'\n",
      "  ‚úÖ wells_joined created\n"
     ]
    }
   ],
   "source": [
    "# Colorado Shapefile and CSV/XLSX Import and Schema Setup\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from sqlalchemy import create_engine, text\n",
    "from zipfile import ZipFile\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define target database (og_impact)\n",
    "db_url = os.getenv(\"OG_IMPACT_DB_URL\")\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Ensure 'co' schema exists\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"CREATE SCHEMA IF NOT EXISTS co\"))\n",
    "\n",
    "# Define download directory and file map\n",
    "base_path = \"/home/dadams/Downloads\"\n",
    "files = {\n",
    "    \"wells\": \"WELLS_SHP.ZIP\",\n",
    "    \"fields\": \"COGCC_FIELDS_SHP.zip\",\n",
    "    \"inspections\": \"Inspections_csv_20240601.zip\",\n",
    "    \"violations\": \"NOAV.zip\",\n",
    "    \"complaints\": \"Complaints.zip\"\n",
    "}\n",
    "\n",
    "for name, zip_file in files.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    zip_path = os.path.join(base_path, zip_file)\n",
    "\n",
    "    if zip_file.lower().endswith(\".zip\"):\n",
    "        try:\n",
    "            # Try reading as shapefile layer\n",
    "            layers = fiona.listlayers(f\"zip://{zip_path}\")\n",
    "            print(f\"  Found layers: {layers}\")\n",
    "            gdf = gpd.read_file(f\"zip://{zip_path}\", layer=layers[0])\n",
    "\n",
    "            # Assign CRS if missing\n",
    "            if gdf.crs is None:\n",
    "                gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "            gdf.to_postgis(name=name, con=engine, schema=\"co\", if_exists=\"replace\", index=False)\n",
    "\n",
    "        except Exception as shapefile_error:\n",
    "            # Fallback: handle CSV or XLSX\n",
    "            with ZipFile(zip_path, 'r') as zip_ref:\n",
    "                csv_names = [f for f in zip_ref.namelist() if f.endswith(\".csv\")]\n",
    "                xlsx_names = [f for f in zip_ref.namelist() if f.endswith(\".xlsx\")]\n",
    "\n",
    "                if csv_names:\n",
    "                    csv_filename = csv_names[0]\n",
    "                    zip_ref.extract(csv_filename, base_path)\n",
    "                    df = pd.read_csv(os.path.join(base_path, csv_filename))\n",
    "                    df.to_sql(name=name, con=engine, schema=\"co\", if_exists=\"replace\", index=False)\n",
    "                    os.remove(os.path.join(base_path, csv_filename))\n",
    "\n",
    "                elif xlsx_names:\n",
    "                    xlsx_filename = xlsx_names[0]\n",
    "                    zip_ref.extract(xlsx_filename, base_path)\n",
    "                    df = pd.read_excel(os.path.join(base_path, xlsx_filename))\n",
    "                    df.to_sql(name=name, con=engine, schema=\"co\", if_exists=\"replace\", index=False)\n",
    "                    os.remove(os.path.join(base_path, xlsx_filename))\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(f\"No CSV or XLSX file found in {zip_file}\")\n",
    "\n",
    "print(\"‚úÖ All Colorado files processed and stored in 'co' schema.\")\n",
    "\n",
    "# Summarize row counts in 'co' schema\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'co'\n",
    "        ORDER BY table_name;\n",
    "    \"\"\")).fetchall()\n",
    "\n",
    "    print(\"üìã Table summary in 'co' schema:\")\n",
    "    for row in result:\n",
    "        table = row.table_name\n",
    "        count = conn.execute(text(f\"SELECT COUNT(*) FROM co.{table}\")).scalar()\n",
    "        print(f\"- {table}: {count} rows\")\n",
    "\n",
    "# Attempt spatial join to counties if geometry column exists\n",
    "counties_gdf = gpd.read_postgis(\"SELECT county_fips, name, geom FROM counties\", con=engine, geom_col=\"geom\")\n",
    "\n",
    "print(\"üîÅ Performing spatial joins where applicable:\")\n",
    "for row in result:\n",
    "    table = row.table_name\n",
    "    try:\n",
    "        gdf = gpd.read_postgis(f\"SELECT * FROM co.{table}\", con=engine, geom_col='geometry')\n",
    "        if gdf.crs is None:\n",
    "            gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "        gdf = gdf.to_crs(counties_gdf.crs)\n",
    "        if 'geometry' in gdf.columns:\n",
    "            gdf = gdf.set_geometry('geometry')\n",
    "        elif 'geom' in gdf.columns:\n",
    "            gdf = gdf.set_geometry('geom')\n",
    "        else:\n",
    "            raise ValueError(\"No geometry column found\")\n",
    "\n",
    "        joined = gpd.sjoin(gdf, counties_gdf, how=\"left\", predicate=\"within\")\n",
    "        joined.to_postgis(name=f\"{table}_joined\", con=engine, schema=\"co\", if_exists=\"replace\", index=False)\n",
    "        print(f\"  ‚úÖ {table}_joined created\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Skipping {table} (no geometry or join failed): {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
